% LTeX: language=pt-br
\documentclass[a4paper,oneside,reqno,12pt]{amsart}

\usepackage[brazilian]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[hyperref=true,%
            backend=biber,%
            language=english,%
            doi=false,%
            url=true,%
            isbn=false,%
            firstinits=true,% 
            urldate=short,%
            sortcites=true,%
            style=numeric,%
            maxcitenames=2,%
            maxbibnames=1000,%
            arxiv=abs,%
            related=true,%
            backref=false,%
            abbreviate=false,%
            dateabbrev=false]{biblatex}
\addbibresource{bib.bib}
%----------------------------



\usepackage{amssymb}
\usepackage{bbm} % for blackboard 1, i.e., \mathbbm{1}
\usepackage{bm}
\usepackage{mathtools}          % already includes amsmath
\usepackage{amsthm}
\usepackage{mathrsfs}           % for \mathscr


\usepackage{suffix}
\usepackage{enumerate}
\usepackage{fullpage}
\usepackage{setspace}
\usepackage{url}
\usepackage{color}
\usepackage{nicefrac}
\usepackage[left=2.25cm,right=2.25cm]{geometry}


\makeatletter
\def\@setdate{Data:\ \@date}
\def\@setaddresses{\vfill\par
  \nobreak \begingroup
\footnotesize
  \def\author##1{\nobreak\addvspace\bigskipamount}%
  \def\\{\unskip, \ignorespaces}%
  \interlinepenalty\@M
  \def\address##1##2{\begingroup
    \par\addvspace\bigskipamount\noindent
    \@ifnotempty{##1}{(\ignorespaces##1\unskip) }%
    {\scshape\ignorespaces##2}\par\endgroup}%
  \def\curraddr##1##2{\begingroup
    \@ifnotempty{##2}{\nobreak\noindent{\itshape Endereço}%
      \@ifnotempty{##1}{, \ignorespaces##1\unskip}\/:\space
      ##2\par}\endgroup}%
  \def\email##1##2{\begingroup
    \@ifnotempty{##2}{\nobreak\noindent{\itshape E-mail}%
      \@ifnotempty{##1}{, \ignorespaces##1\unskip}\/:\space
      \ttfamily##2\par}\endgroup}%
  \def\urladdr##1##2{\begingroup
    \@ifnotempty{##2}{\nobreak\indent{\itshape URL}%
      \@ifnotempty{##1}{, \ignorespaces##1\unskip}\/:\space
      \ttfamily##2\par}\endgroup}%
  \addresses
  \endgroup
}
\makeatother


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                      %%
%%         COLOR MACROS                 %%
%%                                      %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{xcolor}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\blue}[1]{{\color{blue}#1}}
\newcommand{\purple}[1]{{\color{purple}#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                      %%
%%         CUSTOM PACKAGES              %%
%%                                      %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{notation}
\usepackage{decorated}
\usepackage{minimalnickstyle}
\usepackage{theorems}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{ifpdf}
\ifpdf
\usepackage[pdftex,%
            pdfauthor={Paulo Henrique Albuquerque dos Anjos de Souza},%
            pdftitle={Reunião 7 de Maio},%
            % colorlinks=true,%
            % linkcolor=black,%
            % citecolor=black,%
            % urlcolor=black,%
            hypertexnames=true,%
            bookmarks=true]{hyperref}
\usepackage{cleveref}
\else
\fi

\renewcommand*{\bibfont}{\small}

\begin{document}

\baselineskip=1.2\baselineskip
\frenchspacing

\pagenumbering{roman}
% \include{title-page-english}
% \include{title-page-port}

\pagenumbering{arabic}
\setcounter{page}{1}

\title{%
{\small\sl Tcc}\\
\smallskip
Algoritmos de predição para caching}

\author{%
Paulo Henrique Albuquerque dos Anjos de Souza \\
{\tiny\emph{Orientador}:  Victor Sanches Portella}
}
%
% \address{Instituto de Matemática e Estatística, Universidade de São
%   Paulo, R. do Matão 1010, 05508-090, São Paulo, SP}
%
\email{paulodosanjos@usp.br}

\date{\today}
\maketitle

\pagestyle{plain}
\footskip=25pt

\vspace{-20pt}


\section{Introdução}

\subsection{Algortimos de predição e o problema de caching}

Visão geral do TCC, organização, objetivos, etc...

\section{O problema de caching}

O problema de caching (ou de paginação) surge num sistema de memória de dois níveis. Uma memória rápida ou cache tem capacidade de $k$ páginas e uma memória guarda $n$ páginas, onde geralmente $n >> k$.

Uma sequência de índices de páginas, chamada de sequência de entrada ou sequência de pedidos, é fornecida e deve ser servida em ordem. Para que seja servida, todo o pedido individual $p$ deve ser servido, isso acontece quando (i) $p$ está no cache; nesse casos, dizemos que houve um \textit{acerto de cache}; (ii) $p$ não está no cache e uma página $q$ (escolhida de acordo com uma regra de substituição) é descartada do cache para que $p$ entre; dizemos, nesse caso, que houve uma \textit{falha de cache}.

\subsection{Algoritmos determinísticos}

\subsubsection{Algoritmos online vs offline e análise competitiva}

Em particular, estamos interessados no cenário online, onde os pedidos são servidos um por vez. Um algoritmo que resolve o problema, então, deve tomar decisões sequencialmente sem conhecimento dos pedidos futuros. 

É simples imaginar algum algoritmo que resolva o problema de caching descrito acima. Por exemplo, pode-se escolher aleatoriamente uma página do cache para sair numa falha. Naturalmente, queremos analisar esses possíveis algoritmos e comparar seus desempenhos. Em análise de algoritmos clássica, é muito comum fazer análise de pior caso para medir os desempenhos dos algoritmos de um dado problema. No cenário online, geralmente é inútil utilizar essa métrica de desempenho. De fato, é não é difícil ver que sempre é possível encontrar uma entrada patológica que incorra um custo ilimitado para qualquer algoritmo determinístico; isso torna inviável a comparação de algoritmos baseada nessa métrica. Portanto, usamos outra forma de analisar e comparar algoritmos online. Essa forma alternativa é chamada de \textit{análise competitiva}. \footnote {definição técnica de análise competitiva} De forma geral, na análise competitiva, o desempenho de um algoritmo é comparado com o desempenho um algoritmo ótimo quando processam a pior entrada (que resulta na maior discrepância). A razão entre os desempenhos é chamada de competitividade de um algoritmo e é usada para comparar diferentes algoritmos. Pela descrição de competitividade acima, almejamos algoritmos com competitivade baixa, com a razão mais próxima possível de 1. Intuitivamente, é como se cada sequência de entrada tivesse um custo intrínseco, que seria o custo incorrido pelo algoritmo ótimo.

Inicialmente, olhamos para algoritmos determinísticos, isto é, que não possuem um gerador de números aleatórios para auxiliar suas decisões. Nesse caso, a competitividade é calculada usando um algoritmo offline ótimo. Esse algoritmo não é online e, portanto, possui conhecimento de toda a sequência de pedidos a prior. Cada algoritmo é descrito pela forma em que escolhe páginas para sair numa falha de cache.

\subsubsection{Políticas clássicas}

Vejamos algumas políticas (isso é, regra de substituição de páginas) clássicas. 

Uma regra simples intuitiva é que o cache não deveria descartar páginas que serão requisitadas no futuro próximo. Um algoritmo online deve tomar uma decisão que se  sem conhecimento dos pedidos futuros. 

Least Recently Used (LRU): descarta a página no cache cujo pedido mais recente ocorreu mais no passado.

First-in, First-out (FIFO): descarta a página que está há mais tempo no cache.

Least Frequently Used (LFU): descarta a página no cache que foi menos requisitada no passado.

Cada política envolve um custo computacional distinto. Mas o foco inicial é o custo do problema de paginação, isto é, a quantidade de cache misses numa sequência de pedidos.

Voltaremos para essas políticas clássicas depois.

\subsubsection{Política ótima}

Belady (1967) propôs um simples algoritmo offline ótimo para o problema de paginação. A política do algoritmo de Belady é descartar a página que permanecerá sem pedidos pelo maior tempo no futuro. Essa política é chamada de Furthest-in-the-Future ou algoritmo MIN. Aqui chamaremos simplesmente de OPT.

A prova de otimalidade desse algoritmo guloso não é trivial, então daremos somente o esboço da prova mais adiante.

\subsubsection{Formalização inicial}

Agora, fixemos a notação que usaremos ao longo do texto.

Sejam $\Omega$ um conjunto de páginas numeradas de $1$ a $|\Omega|=n$, $f: [n]^{*} \to \mathcal{P}([n])$ e $\sigma_t \in [n]$ uma sequência de páginas, onde $[m] = \iinterval{1}{m}$. Definimos $\sigma_{1:t} \coloneqq (\sigma_1, \sigma_2, \dots, \sigma_t),\ t \in [|\sigma|]$, $B^{*} = \cup_{i=0}^{\infty} B^{i}$ e $\Powerset{B} = \{ X \mid X \subseteq B \}$. Dizemos que $f$ é um algoritmo para o problema de cache de tamanho $k$ se satisfaz as condições abaixo:

\begin{equation}
  f(\emptyset)  = [k] \quad \text{Estado inicial do cache}
\end{equation}
    %|f(\sigma)| \  = k, \quad \forall \ \sigma \in [n]^{*} \quad \text{Capacidade do cache} = k \\
    %\sigma_t \in f(\sigma_{1:t}), \quad \forall \ t \in [|\sigma|] \quad \text{Condição do cache} \\

Considere um algoritmo de cache (de tamanho $k$) $A$ e uma sequência de páginas $\sigma$. Definimos os conjuntos $S_0 = [k] = A(\emptyset)$ e $S_t = A(\sigma_{1:t}), t \in [|\sigma|]$ que representam o conjunto de páginas que o cache guarda imediatamente após o tempo $t$. Observe que impomos, sem perda de generalidade (nossa análise não levará em conta condições iniciais) que o cache comeca com as $k$ primeiras páginas. Nessa formulacão, o algoritmo pode trocar quantas páginas quiser em cada turno, desde que $\sigma_t \in S_t$ e $|S_t| = k$.

Note que essa formulacao permite tratar algortimos online de forma natural: $A(\emptyset) = [k]$, $A((\sigma_1)) = S_1$, $A((\sigma_1, \sigma_2)) = S_2$ e assim por diante o algortimo vai servindo pedidos sequencialmente sem informacão dos pedidos futuros. Para um algoritmo offline $A_{\sigma}$ a formulacão não funciona exatamente mas convencianos que o algortimo ainda é uma funcao do tipo descrito acima mas que é implementado com toda a sequencia visivel, o subscrito sinaliza isso. 

. Em seguida, definimos o custo $\text{Custo}(A, \sigma)$ incorrido quando $A$ processa $\sigma$:

\begin{equation}
  \text{Custo}(A, \sigma) = \sum_{t=1}^{|\sigma|} |A(\sigma_{1:t}) - A(\sigma_{1:t-1}))|
\end{equation}

que é a quantidade total de troca de páginas. Note que acima o símbolo "-" denota subtracão de conjuntos, similarmente usaremos "+" para denotar adicão de conjunto ou adicão de um conjunto com um elemento.

Em geral, lidaremos com algoritmos que trocam uma única página quando ocorre um cache miss. Nesse caso, o algoritmo implementa uma política $\text{POL}: (S_t, \sigma) \to [n]$ e o custo total é a quantidade de cache misses.

Como definir politicas independente de $S_t$? Lembrar que a notacao servira mais como orientacao do que como algo estrito no problema em questao.

\subsubsection{C-competitividade}

Agora, munidos de um algoritmo ótimo real, definimos formalmente a noção de competitividade:

\begin{definition}
Um algoritmo online para o problema de paginação $A$ é dito C-competitivo se existe uma constante b tal que para toda sequência de pedidos $\sigma$:

\[f_A(\sigma) \leqslant C \times f_{OPT}(\sigma) + b\]

para alguma constante $b$ independente de $N$.
\end{definition}

Vemos aqui a ideia de medir o desempenho de um algoritmo online como a razão de custos entre o algoritmo offline ótimo. $C$ é chamado de coeficiente de competitividade. Se tomarmos o menor $C$ que satisfaça a definição para o algoritmo $A$, denotamos o por $C_A$, o coeficiente competitivo de $A$.

A partir daí, podemos nos perguntar qual o coeficiente de competitividade das estratégias clássicas LRU, FIFO e LFU e portanto, qual, baseado nessa métrica, é a melhor política?

Antes de responder essas perguntas, vejamos um resultado geral. Provaremos uma cota inferior no coeficiente de competitividade de algoritmos online determinísticos.

\subsection{Resultados premiminares para algortimos determinísticos}

\subsubsection{Cota inferior para algoritmos online determinísticos}

\begin{theorem}
\label{teorema1}
Todo algoritmo de paginação online determinístico $A$ tem coeficiente de competitividade ao menos $k$. Isto é, $C_A \geqslant k$.
\end{theorem}

\begin{proof}

Fixemos $n = k + 1$. Sabemos que, como $A$ é determinístico, existe uma sequência $\sigma_p$ que faz $A$ falhar em todos os $T = |\sigma_p|$ pedidos. Calculemos $f_{FIF}(\sigma_p)$. 

Seja $\tau_t(i)$ o menor tempo $t'$ maior que $t$ tal que $\sigma_{t'} = i$, ou seja, é o tempo do próximo pedido da página $i$ a partir de $t$.



Suponha que em algum ponto da sequência ocorreu um cache miss. Evidentemente, OPT deve escolher uma página $p$ para descartar dentre $k$ candidatas, o tamanho do cache. Devido a política de OPT (Furthest-in-the-Future), $p$ só poderá ser solicitada novamente depois de todas as outras $k - 1$ páginas, caso contrário, ela não teria sido escolhida. E, como todas essas outras $k - 1$ páginas estão no cache, só ocorrerá cache hits, de fato, no mínimo $k - 1$, no caso em que cada outra página é solicitada somente uma vez.

Ou seja, OPT segue cada falha com ao menos $k-1$ acertos. Daí segue que:

\[\text{\# cache misses} + \text{\# cache hits} = N\]

\[ \text{\# cache hits} \geqslant \text{\# cache misses} \times (k-1)\]

\[\text{\# cache misses} \leqslant N/k\]

\[f_{OPT}(\sigma_p) \leqslant f_A(\sigma_p) / k\]

\[f_A(\sigma_p)/f_{OPT}(\sigma_p) \geqslant k\]

Logo, $C_A \geqslant k$.
\end{proof}


\subsubsection{Competitividade do LRU}

Finalmente, calculamos o coeficiente de competitividade para a estratégia LRU, que descarta a página com pedido recente mais antigo.

\begin{theorem}
O coeficiente de competitividade do algoritmo LRU é igual ao tamanho do cache. Isto é, $C_{LRU} = k$.
\end{theorem}

\begin{proof}
Seja $\sigma$ uma sequência qualquer. Dividimos $\sigma$ em blocos $b_1, b_2, ... b_{m}$, onde 
\begin{itemize}
    \item $b_1$ é o maior prefixo de $\sigma$ que contém no máximo $k$ páginas distintas.
    \item $b_i$ ($1 < i \le m$) começa imediatamente após $b_{i-1}$ e termina no ponto anterior ao pedido que faria o total de páginas distintas no bloco ultrapassar $k$. 
\end{itemize}

Nossa prova consiste em contar a quantidade de cache misses para LRU e OPT dentro dos blocos.

Considere o ponto em que ocorreu um cache miss para o pedido de uma página $p$ no bloco $b$.

Nesse ponto, $p$ é a página mais recentemente solicitada e, para a política LRU, está no fim da fila de prioridade para sair novamente. Observe que ela não voltará ao início da fila enquanto o bloco $b$ não acabar. De fato, o cache nesse ponto contém $k-1$ páginas com prioridade de saída maior que $p$ e, pela definição de bloco, ocorrerão pedidos a no máximo $k-1$ páginas distintas: $p$ está garantido de não sair novamente nesse bloco. Como $p$ é arbitrário, segue que cada página de um bloco pode aumentar em no máximo um o custo total e como há $k$ páginas por bloco, um bloco pode falhar no máximo $k$ vezes. Então, LRU incorre um custo no máximo $km$, onde $m$ é a quantidade de blocos em $\sigma$.

Para OPT, o argumento é um pouco diferente. Considere o bloco $b_1$ mais o primeiro pedido $p$ de $b_2$. Esse conjunto contém $k+1$ páginas distintas, e como o cache tem tamanho $k$, nenhum algoritmo poderá servir esse conjunto sem falhar ao menos uma vez. Após servir o pedido $p$, o cache deve conter somente $k-1$ páginas diferentes de $p$. Mas, como $\sigma_2$ é maximal, o restante de $\sigma_2$ mais o primeiro pedido de $\sigma_3$ contém pedidos para $k$ páginas diferentes de $p$, incorrendo em pelo menos uma falta nesse conjunto. E assim por diante, resultando em pelo menos $b - 1$ cache misses (se houver um só bloco OPT não falha).

Então, 

\[f_{LRU}(\sigma)/f_{OPT}(\sigma) \le kb/(b-1)\]

Segue que existem sequências arbitrariamente longas em que LRU erra no máximo $k$ vezes menos do que OPT.

Pela definição de coeficiente de competitividade, fica fácil ver que $C_{LRU} \ge k$. Pelo Teorema \ref{teorema1}, nenhum algoritmo online determinístico pode ter coeficiente maior que $k$. Logo, $C_{LRU} = k$.
\end{proof}


\subsubsection{Prova de otimalidade da política Furthest-in-the-Future}

...

\subsection{Modelos de adversários}

O teorema x dá a melhor competitividade para algoritmos determinísticos. Agora, damos um passo a frente e vejamos o que podemos falar sobre algoritmos aleatorizados. Para continuar nossa análise competitiva introduzimos o conceito de adversários e, em seguida, veremos as relações entre os tipos de adversários.

Um algoritmo aleatorizado $R$ é munido com um gerador de bits aleatórios que permite que descarte itens aleatoriamente após um cache miss. Claramente, o custo $Custo(R,\sigma)$ passa a ser uma variável aleatória. Para os algoritmos determinísticos, como vimos, a noção de competitividade é estrita: $A$ processa online uma sequência $\sigma$ e seu custo é comparado com $Custo(\text{MIN}, \sigma)$. O mesmo não acontece para algoritmos aleatorizados. De fato, como veremos em seguida, podemos ter três formas diferentes de competitividade, resumidas nos três tipos de \textit{adversários}. 

Na análise competitiva, para medir o desempenho de um algoritmo online $A$, seja ele determinístico ou aleatorizado, comparamos seu custo com o custo de um algoritmo de referência mais "poderoso" para a mesma sequência. 
A partir de agora, por motivos que ficarão claros, usaremos o termo \textit{adversário} para nos referimos a esse algoritmo de referência. Um adversário agora ganha uma dimensão maior e seu comportamento varia de acordo com o tanto de informação que possui de $A$. O adversário também vai ser o encarregado de produzir a sequência de entrada $\sigma$ que será usada para os cálculos de custo. O "objetivo" do adversário então é construir entradas patológicas que, no melhor dos mundos, piore o desemepenho de $A$ e melhore o seu. Definimos, então, três tipos de adversários, agora verbalmente e mais adiante rigorosamente, baseado nisso:

\begin{definition}
  Um adversário $Q$ é um adversário \textit{simples} se possui conhecimento do funcionamento de $A$, mas não tem acesso as escolhas aleatórias dele.
\end{definition}

Esse é o adversário mais fraco possível. Já que não enxerga as respostas de $A$, pode muito bem construir sua entrada $\sigma$ antes de $A$ processar. Agora, passamos aos outros dois tipos de adversários, chamados de \textit{adaptativos}. São algortimos que além de enxergarem o "esqueleto" de $A$, tem acesso a cada tempo as respostas de $A$, isto é, as páginas escolhidas aleatoriamente para descarte. Um adversário desse tipo escolhe $\sigma_t$ com base nas respostas (conhecidas por ele) de $A$ quando esse processa $\sigma_1, \sigma_2, \dots, \sigma_{t-1}$.


\begin{definition}
  Um adversário adaptativo $Q$ é um adversário adaptativo \textit{offline} se, após gerar $\sigma$, usa o MIN para gerar seu custo. Isto é, Custo$(Q, \sigma) = \text{Custo}(MIN, \sigma)$.
\end{definition}

\begin{definition}
  Um adversário adaptativo $Q$ é um adversário adaptativo \textit{online} se, mantém seu próprio cache online. Em outras palavras, constrói $\sigma$ observando a cada tempo as respostas de $A$, assim como o adversário offline, mas a cada tempo também dá sua resposta (página a ser descartada). 
\end{definition}


\subsubsection{Competitividade para algortimos aleatorizados}

Analogamente ao que foi feito para algortimos determinísticos, podemos definir o coeficiente de competitividade para algortimos aleatorizados. A única diferença na definição surge no fato que, agora, o custo $Custo(R, \sigma)$ é uma variável aleatória.

\begin{definition}
  Dizemos que um algoritmo aleatorizado $R$ para o problema de caching é $C$-competitivo se para toda sequência $\sigma$ existe uma constante $b$ tal que
  \begin{equation}
    \mathbb{E}[\text{Custo}(R, \sigma)] - C \times \mathbb{E}[\text{Custo}(Q, \sigma)] \leqslant b
  \end{equation}
  
\end{definition}

O coeficiente de competitividade de $R$, denotado $C_R$ é o infímo de $C$ tal que $R$ é $C$-competitivo.

De acordo com o tipo de $Q$, temos diferentes formas de calcular $\text{Custo}(Q, \sigma)$ e, portanto, diferentes coeficientes para o mesmo algortimo $R$. Isso será indicado por um sobescrito em $C_R$: se $Q$ é um adversário simples, denotamos o coeficiente de competitivade de $R$ por $C_R^{\text{s}}$, se é um adversário adaptativo offline, por $C_R^{\text{off}}$ e, finalmente, se é um adversário adaptativo online, por $C_R^{\text{on}}$. A pergunta natural que surje é qual a relação entre essas quantidades para um mesmo algoritmo $R$.

\subsubsection{Relações entre as competitividades}

Claramente, o adversário offline é mais poderoso que o online, pois o primeiro pode "esperar" para dar sua resposta após toda sequência ser gerada. O adversário online é forçado a dar suas respostas a cada tempo. Por último, em termos de poder, vem o adversário simples, que possui menos informação que os dois primeiros a cada tempo. Quanto menos "poder" $Q$ possui, mais chances $R$ tem de ter um comportamento melhor comparado ao adversário, evidentemente. Um desempenho melhor se traduz por um coeficiente de competitiva mais próximo de um. Portanto, é de se esperar que:

\begin{equation}
  C_R^{\text{s}} \leqslant C_R^{\text{on}} \leqslant C_R^{\text{off}}
\end{equation}

Agora, se olharmos para a classe de algortimos $R$, podemos definir $C^{s}$ como o menor coeficiente de competitividade de qualquer algoritmo $R$, analogamente, definimos $C^\text{{on}}$ e $C^\text{{off}}$. Além disso, definimos $C^{\text{det}}$, o menor coeficiente de competitividade de qualquer algoritmo determinístico, esse, certamente, tem menores chances contra um adversário ótimo offile, visto que o último tem total conhecimento do comportamento do primeiro. Logo, da equação x, conclui-se:

\begin{equation}
  C_R^{\text{s}} \leqslant C_R^{\text{on}} \leqslant C_R^{\text{off}} \leqslant C^{\text{det}}
\end{equation}

Naturalmente, surge a pergunta sobre como esses coeficientes se relacionam. Essa inverstigação nos dará resultados gerais sobre os tipos de adversários e quão "bom" pode ser um algoritmo aleatorizado enfrentando esses adversários.


\subsubsection{Cota inferior para um adversário oblivious}

Primeiramente, provamos um teorema importante. Que nos diz sobre o poder de um adversário simples.

\begin{theorem}
  Seja $R$ um algoritmo aleatorizado para o problema de caching. Então, $C_R^{\text{s}} \geqslant H_k$, onde $H_k = \sum_{j = 1}^{k} 1/j$ é o $k$-ésimo número harmônico.
  \begin{proof}
  \end{proof}
\end{theorem}


\subsubsection{Algortimo Marker}

Descrevemos um famoso algoritmo aleatorizado para o problema de caching que atinge competitividade próxima ao limite inferior do teorema x.

Algoritmo Marker: 

\begin{theorem}

  O algoritmo Marker é ($2H_k$)-competitivo.
  
  \begin{proof}
    
  \end{proof}
  
\end{theorem}


Existe um algoritmo que atinge competitividade $H_k$ em geral.

\subsection{Notação funcional para adversários}

A seção anterior mostra que existem algoritmos aleatorizados com competitividade simples substancialmente menor do que qualquer algoritmo determinístico, visto que $H_k = O(log k)$, enquanto, pelo teorma x, algoritmos determinísticos têm competitividade no mínimo $k$.

Investigamos agora se uma situação semelhante acontece com adversários adaptativos. Ou seja, se é possível construir algoritmos com coeficientes de competitividade baixos. Veremos que não é possível e concluímos então que os adversários adapativos provam ser relativamente poderosos se comparados com adversários simples.

Mas antes, vamos definir formalmente algoritmos aleatorizados com a mesma notação usada para algoritmos determinísticos.



Em sequida, provamos dois teoremas importantes sobre competitividade.

\subsubsection{Teorema $\alpha$-competitivo}

\begin{theorem}

  Se existe um algoritmo aleatorizado que é $\alpha$ competitivo contra qualquer adversário offline, então existe um algoritmo determinístico $\alpha$-competitivo.

  \begin{proof}
  \end{proof}

\end{theorem}

Pelos teoremas x e y, segue que não existe algoritmo $c$-compeititivo contra adversários offline com $c < k$. Em contraste com o adversário simples que tinham algoritmos $O(logk)$-competitivos.

\subsubsection{Teorema $\alpha\beta$-competitivo}

\begin{theorem}
  Suponha que exista $R$ algoritmo aleatorizado $\alpha$-competitivo contra qualquer adversário online e um algoritmo $\beta$-competitivo contra qualquer adversário simples. Então, $R$ é $\alpha\beta$-competitivo contra qualquer adversário offline.

  \begin{proof}
  \end{proof}

\end{theorem}

Logo, pelos teoremas x e y:

\[ C^{\text{det}} \leqslant C^{\text{on}}C^{\text{s}} \to 
C^{\text{on}} \geqslant \frac{C^{\text{det}}}{C^{\text{s}}} = \Omega(k/H_k)
\] 



\subsection{Adversário adaptativo online}

Nessa seção, buscamos calcular $C^{\text{on}}$. Para isso, estudos um problema de paginação mais geral.

\subsubsection{Problema de paginação com pesos}

Cada página $p$ é associada com uma função peso $w(p)$. O problema é idêntico com o problema de cache definido acima, com excessão da função custo:

\[
  \text{Custo}(A, \sigma) = \sum_{t=1}^{|\sigma|} w(A(\sigma_{1:t}) - A(\sigma_{1:t-1})))]
\]

Evidentemente, se $w(p) = 1 \forall p \in [n]$, o problema se reduz para o problema de cache básico.

\subsubsection{Reciprocal}

\subsubsection{Random algorithm e conclusões}

\subsection{Problema dos $k$-servidores}

\section{Introduzindo predições}

\begingroup
\setstretch{1.2}
\printbibliography
\endgroup

\normalsize


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                      %%
%%         SIGNATURE STUFF              %%
%%                                      %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \hfill
% São Paulo, \makeatletter\@date\makeatother.

% \vspace{1.5cm}

% \hfill
% {\em Host: Yoshiharu Kohayakawa}

\end{document}

%%% Local Variables:
%%% coding: utf-8
%%% mode: latex
%%% TeX-master: t
%%% default-input-method: portuguese-prefix
%%% End:
